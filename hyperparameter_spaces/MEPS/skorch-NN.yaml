MLP:
    classpath: utils.wrappers.skorch.FeedForwardClassifier

    kwargs:
        batch_size:
            - 250
            - 1000

        # Training params
        max_epochs:
            type: int
            range: [5, 250]
            log: True

        module__hidden_layers:
            - [ 20 ]
            - [ 20, 20 ]
            - [ 20, 20, 20 ]
            - [ 100 ]
            - [ 100, 100 ]
            - [ 100, 100, 100 ]
            - [ 500 ]
            - [ 500, 500 ]
            - [ 2500 ]

        module__use_batch_norm:
            - True
            - False

        module__dropout:
            type: float
            range: [ 0, 0.4 ]

        # Optimizer params
        optimizer__lr:
            type: float
            range: [ 0.0001, 0.01 ]
            log: True

        optimizer__weight_decay:
            - 0
            - 0.01
            - 0.0033
            - 0.0010
            - 0.00033
            - 0.00010

        optimizer__amsgrad:
            - True
            - False
